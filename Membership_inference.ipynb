{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44e18adf-c4ef-4f2b-8000-56681d980f17",
   "metadata": {},
   "source": [
    "# Membershif Inference attack\n",
    "\n",
    "To run the notebook:\n",
    "```jupyter nbconvert --execute  -to notebook --inplace Membership_inference.ipynb```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e02f2c1-40aa-479c-9816-602b94092cdc",
   "metadata": {},
   "source": [
    "## Dataset Selection\n",
    "select a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0cde1a8-a6e6-4e08-9ed2-aa4a152a3644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ipywidgets import interact, widgets\n",
    "import ipywidgets as widgets\n",
    "\n",
    "dataset = 'purchase-100'\n",
    "dataset_list = ['purchase-10', 'purchase-20', 'purchase-50', 'purchase-100', 'texas', 'MNIST', 'synthetic', 'Census', 'DNA']\n",
    "\n",
    "from data_preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf591e1-0303-4863-b5e5-795d5c462ef0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T10:12:54.760234Z",
     "iopub.status.busy": "2023-07-09T10:12:54.758548Z",
     "iopub.status.idle": "2023-07-09T10:12:54.783346Z",
     "shell.execute_reply": "2023-07-09T10:12:54.781970Z"
    }
   },
   "source": [
    "## Attack Parameters\n",
    "set the attack parameters for the test below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9232ca5-2fcf-4523-9ead-16c02b67e079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "378b45e2-775f-40ee-8618-c64845145ea9",
   "metadata": {},
   "source": [
    "## Defence Parameters\n",
    "set the defence parameters below\n",
    "\n",
    "most of the settings can be set in config.py!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d5c262b-1295-47f4-a552-842e81c5bd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from federated_xgboost.FLTreeHMulti import H_PlainFedXGBoost # USE HMULTI\n",
    "from federated_xgboost.XGBoostCommon import XgboostLearningParam, PARTY_ID \n",
    "from config import CONFIG, dataset, rank, logger, comm\n",
    "from data_structure.DataBaseStructure import QuantileParam\n",
    "from algo.LossFunction import LeastSquareLoss, LogLoss, SoftMax\n",
    "\n",
    "\n",
    "XgboostLearningParam.LOSS_FUNC = SoftMax()\n",
    "XgboostLearningParam.LOSS_TERMINATE = 50 # this is not done right now in the multi-class approach!\n",
    "XgboostLearningParam.GAMMA = CONFIG[\"gamma\"]\n",
    "XgboostLearningParam.LAMBDA = CONFIG[\"lambda\"]\n",
    "QuantileParam.epsilon = QuantileParam.epsilon\n",
    "QuantileParam.thres_balance = 0.3\n",
    "\n",
    "XgboostLearningParam.N_TREES = CONFIG[\"MAX_TREE\"]\n",
    "XgboostLearningParam.MAX_DEPTH = CONFIG[\"MAX_DEPTH\"]\n",
    "\n",
    "\n",
    "if CONFIG[\"model\"] == \"PlainXGBoost\":\n",
    "    model = H_PlainFedXGBoost(XgboostLearningParam.N_TREES, 10)\n",
    "\n",
    "logger.warning(\"TestInfo, {0}\".format(CONFIG))\n",
    "logger.warning(\"XGBoostParameter, nTree: %d, maxDepth: %d, lambda: %f, gamma: %f\", \n",
    "XgboostLearningParam.N_TREES, XgboostLearningParam.MAX_DEPTH, XgboostLearningParam.LAMBDA, XgboostLearningParam.GAMMA)\n",
    "logger.warning(\"QuantileParameter, eps: %f, thres: %f\", QuantileParam.epsilon, QuantileParam.thres_balance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce8446c-81e0-49be-90de-4d0f50e34497",
   "metadata": {},
   "source": [
    "## Assesment Parameters\n",
    "set plotting and other evaluating settings below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03ee9d3-6d56-429f-a1c7-54780c31c718",
   "metadata": {},
   "source": [
    "## Membership Inference Attack\n",
    "How the membership Inference attack is done can be seen below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a591aa-ed65-4cec-b307-3108e197be21",
   "metadata": {},
   "outputs": [],
   "source": [
    "if rank != -1:\n",
    "    if CONFIG[\"dataset\"] == dataset[0]:\n",
    "        y_pred, y_test, model = test_iris(model)\n",
    "    elif CONFIG[\"dataset\"] == dataset[1]:\n",
    "        y_pred, y_test, model = test_give_me_credits(model)\n",
    "    elif CONFIG[\"dataset\"] == dataset[2]:\n",
    "        y_pred, y_test, model = test_adult(model)\n",
    "    elif CONFIG[\"dataset\"] == dataset[3]:\n",
    "        y_pred, y_test, model = test_default_credit_client(model)\n",
    "    elif CONFIG[\"dataset\"] == dataset[4]:\n",
    "        y_pred, y_test, model = test_aug_data(model)\n",
    "    elif CONFIG[\"dataset\"] == dataset[5]:\n",
    "        y_pred, y_test, model = test_texas(model) # TODO make\n",
    "    elif CONFIG[\"dataset\"] == dataset[6]:\n",
    "        y_pred, y_test, model = test_purchase(model)\n",
    "    if rank == PARTY_ID.SERVER:\n",
    "        # model.log_info()\n",
    "        import pickle\n",
    "        pickle.dump({\"model\":model, \"y_pred\":y_pred, \"y_test\":y_test}, open( \"debug.p\", \"wb\"))\n",
    "        # target_model = pickle.load(open(TARGET_MODEL_NAME, \"rb\"))\n",
    "\n",
    "        acc, auc = model.evaluatePrediction(y_pred, y_test, treeid=99)    \n",
    "        print(\"Prediction: \", acc, auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759701c0-2bb0-43f0-b8dc-7fea3357d72c",
   "metadata": {},
   "source": [
    "## Plotting and Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06647515-1f0e-493a-8163-a2c2f39d1c16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
